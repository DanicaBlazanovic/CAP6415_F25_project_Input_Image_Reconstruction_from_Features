{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa22a78-4435-4803-b9c8-469482077949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import torch\n",
    "from models import FeatureExtractor, AttentionDecoder\n",
    "from discriminator import PatchGANDiscriminator\n",
    "from train_adversarial import AdversarialTrainer\n",
    "from dataset import get_dataloaders\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75f31bac-0b39-4fc8-85f4-1f953c3cd3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] vgg16 block1 has large features - using CPU instead of MPS\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Auto-detect safe device\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from train_adversarial import select_device_safe\n",
    "\n",
    "device = select_device_safe('vgg16', 'block1')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e11199e-257c-4ef7-a67d-afef82ce0f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: 64 x 112 x 112\n",
      "Decoder params: 233,667\n",
      "Discriminator params: 2,766,529\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Create models\n",
    "architecture = 'vgg16'\n",
    "layer_name = 'block1'\n",
    "\n",
    "# Encoder (frozen)\n",
    "encoder = FeatureExtractor(architecture=architecture, layer_name=layer_name)\n",
    "encoder.eval()\n",
    "\n",
    "# Get feature shape\n",
    "with torch.no_grad():\n",
    "    dummy = torch.randn(1, 3, 224, 224)\n",
    "    feat = encoder(dummy)\n",
    "    feat_channels, feat_h, feat_w = feat.shape[1:]\n",
    "\n",
    "print(f\"Feature shape: {feat_channels} x {feat_h} x {feat_w}\")\n",
    "\n",
    "# Decoder\n",
    "decoder = AttentionDecoder(\n",
    "    input_channels=feat_channels,\n",
    "    input_size=feat_h,\n",
    "    output_size=224,\n",
    "    num_blocks=4\n",
    ")\n",
    "\n",
    "# Discriminator\n",
    "discriminator = PatchGANDiscriminator(in_channels=3)\n",
    "\n",
    "print(f\"Decoder params: {sum(p.numel() for p in decoder.parameters()):,}\")\n",
    "print(f\"Discriminator params: {sum(p.numel() for p in discriminator.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70fc014f-9ef8-4f3e-935e-9b931c129e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found 10 images in ../data//DIV2K_train_HR\n",
      "✓ Found 10 images in ../data//DIV2K_train_HR\n",
      "✓ Found 100 images in ../data//DIV2K_test_HR\n",
      "Train batches: 4\n",
      "Val batches: 1\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Load small dataset (limit to 10 images for quick test)\n",
    "train_loader, val_loader, _ = get_dataloaders(\n",
    "    data_dir = '../data/',\n",
    "    batch_size=2,\n",
    "    num_workers=0,\n",
    "    limit=10  # Only 10 images for quick test\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5247dbcf-8c24-4522-b8c5-9fb858af0fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer initialized!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Create trainer\n",
    "trainer = AdversarialTrainer(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    discriminator=discriminator,\n",
    "    device=device,\n",
    "    mse_weight=1.0,\n",
    "    adv_weight=0.01,\n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6394f751-1ec8-4d36-b7d1-6d4c0e5260c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch shape: torch.Size([2, 3, 224, 224])\n",
      "Features shape: torch.Size([2, 64, 112, 112])\n",
      "Reconstructed shape: torch.Size([2, 3, 224, 224])\n",
      "Discriminator output shape: torch.Size([2, 1, 26, 26])\n",
      "\n",
      "Forward pass successful!\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Test single batch forward pass\n",
    "test_batch = next(iter(train_loader)).to(device)\n",
    "print(f\"Test batch shape: {test_batch.shape}\")\n",
    "\n",
    "# Encode\n",
    "with torch.no_grad():\n",
    "    features = encoder(test_batch)\n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "\n",
    "# Decode\n",
    "reconstructed = decoder(features)\n",
    "print(f\"Reconstructed shape: {reconstructed.shape}\")\n",
    "\n",
    "# Discriminator\n",
    "D_output = discriminator(test_batch)\n",
    "print(f\"Discriminator output shape: {D_output.shape}\")\n",
    "\n",
    "print(\"\\nForward pass successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51037db3-f306-4d48-9fdf-816df9e8a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing one training step...\n",
      "Discriminator - Loss: 0.7130, D_real: -0.1480, D_fake: -0.1318\n",
      "Generator - Loss: 1.5700, MSE: 1.5528, Adv: 1.7267\n",
      "\n",
      "Training step successful!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Test one training step\n",
    "print(\"Testing one training step...\")\n",
    "\n",
    "# Train discriminator\n",
    "loss_D, D_real, D_fake = trainer.train_discriminator(test_batch, reconstructed)\n",
    "print(f\"Discriminator - Loss: {loss_D:.4f}, D_real: {D_real:.4f}, D_fake: {D_fake:.4f}\")\n",
    "\n",
    "# Train generator\n",
    "loss_G, mse, adv = trainer.train_generator(test_batch, reconstructed)\n",
    "print(f\"Generator - Loss: {loss_G:.4f}, MSE: {mse:.4f}, Adv: {adv:.4f}\")\n",
    "\n",
    "print(\"\\nTraining step successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d46edec-2e69-4732-a27e-575d16793425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 2-epoch test...\n",
      "\n",
      "Epoch 1/2\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████| 4/4 [12:28<00:00, 187.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss_G: 1.329113 (MSE: 1.316924, Adv: 1.218884)\n",
      "Train - Loss_D: 1.112810 (D_real: 0.134, D_fake: -0.371)\n",
      "Val   - Loss_G: 1.060474 (MSE: 1.056406, Adv: 0.406795)\n",
      "LR    - G: 0.001000, D: 0.001000\n",
      "[SAVED] Best model at epoch 1 (val_loss: 1.060474)\n",
      "\n",
      "Epoch 2/2\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|████████████████████████████████████████████████████████████████████████████████████████| 4/4 [12:07<00:00, 181.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss_G: 1.064019 (MSE: 1.053793, Adv: 1.022615)\n",
      "Train - Loss_D: 0.674401 (D_real: -0.171, D_fake: -0.474)\n",
      "Val   - Loss_G: 0.881816 (MSE: 0.875698, Adv: 0.611715)\n",
      "LR    - G: 0.001000, D: 0.001000\n",
      "[SAVED] Best model at epoch 2 (val_loss: 0.881816)\n",
      "\n",
      "[SAVED] Training history: ../results/test_adversarial/metrics_adversarial/training_history.csv\n",
      "\n",
      "2-epoch test complete!\n",
      "Final train loss: 1.0640\n",
      "Final val loss: 0.8818\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Test 2 epochs (should take ~2-3 minutes on CPU)\n",
    "print(\"Running 2-epoch test...\")\n",
    "\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=2,\n",
    "    save_dir='../results/test_adversarial/checkpoints'\n",
    ")\n",
    "\n",
    "print(\"\\n2-epoch test complete!\")\n",
    "print(f\"Final train loss: {history['train_loss_G'][-1]:.4f}\")\n",
    "print(f\"Final val loss: {history['val_loss_G'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c5c2487-729d-4873-954f-92a260113112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0\n",
      "Cell 1 OK\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Just import torch\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(\"Cell 1 OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d717e0-1503-4a74-867c-3c9ae16242da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cv_final)",
   "language": "python",
   "name": "cv_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
