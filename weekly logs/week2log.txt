WEEK 2 LOG - CV Final Project: Input Image Reconstruction from Features

Run 1: Perceptual Loss Investigation

Implementation
- Created train_perceptual.py with combined MSE + LPIPS loss (0.5 + 0.5 weighting)
- Implemented LPIPS using AlexNet backbone
- Built run_perceptual_vgg_block1.py experiment runner
- Created evaluate_perceptual_vgg_block1.py for test set evaluation
- Developed generate_perceptual_comparison.py for baseline vs Run 1 visualization
- Built Colab notebook for A100 GPU training

Training
- Device: Google Colab Pro A100 (40GB)
- Configuration: VGG16 block1, 30 epochs, batch size 1, lr 0.001
- Training time: 163.1 minutes
- Learning rate reduced to 0.0005 at epoch 29
- Checkpoints: best model plus epochs 10, 20, 30

Results
- Test set: 100 images from DIV2K_valid_HR
- PSNR: 13.93 dB (baseline: 14.45 dB, -0.52 dB)
- SSIM: 0.565 (baseline: 0.530, +0.035)
- LPIPS: 0.272 (baseline: 0.398, -0.126, -31.7% improvement)
- Visual analysis: sharper textures, better colors, fewer artifacts

Technical Issues
- MPS memory errors on Mac M1: used CPU for evaluation
- Batch size 1 required for 112x112 features
- CPU evaluation: 15 minutes for 100 images

Documentation
- Added complete Run 1 section to README
- Updated with configuration, results, visual analysis
- Documented PSNR vs LPIPS trade-off

Week 2 Summary
New code: 4 Python files, 1 notebook, ~1200 lines
Experiment: 1 complete 30-epoch run
Key result: 31.7% perceptual quality improvement

---

Run 2: Adversarial Training Implementation

Implementation
- Created discriminator.py with PatchGAN architecture (26×26 patch classification)
- Developed train_adversarial.py with AdversarialTrainer class
- Built run_adversarial_vgg_block1.py experiment runner with 4-panel loss visualization
- Implemented alternating G/D optimization with 1:1 update ratio
- Applied label smoothing (0.9 for real images) for training stability

Configuration
- Architecture: VGG16 block1 (64×112×112 features)
- Loss: Combined MSE + Adversarial (λ_MSE=1.0, λ_adv=0.01)
- Optimizer: Adam (beta1=0.5, beta2=0.999) for both G and D
- Learning rate: 0.001 with ReduceLROnPlateau scheduling
- Training: 30 epochs, batch size 1, A100 40GB GPU

Training Status
- Currently running on Google Colab Pro A100
- Expected completion: [add when available]
- Results will be added to README upon completion

Concurrent Research Activity
- Conducting literature review on state-of-the-art feature inversion methods
- Investigating advanced decoder architectures beyond attention-based design
- Exploring alternative loss functions for perceptual quality optimization
- Benchmarking our approach against published reconstruction methods
- Goal: Identify optimal techniques for neural network feature reconstruction

Next Steps
1. Complete Run 2 training and test set evaluation
2. Generate 3-way comparison visualizations (Baseline vs Run 1 vs Run 2)
3. Analyze PSNR/SSIM/LPIPS trade-offs across all three approaches
4. Update README with Run 2 results and cross-method analysis
5. Based on literature findings, determine if additional experiments warranted

Week 2 Extended Summary
New code (Run 2): 3 Python files, ~800 lines
Experiments: Run 1 complete, Run 2 in progress
Research: Literature review ongoing for optimal reconstruction methods
Results pending: Adversarial training approach (Run 2)