=============================================================================WEEK 4 LOG - CV Final Project: Input Image Reconstruction from Features=============================================================================Run 3: Multi-Architecture Ensemble InvestigationImplementation- Created models.py with modular architecture:  - ResNetExtractor, VGGExtractor, ViTExtractor, PVTExtractor classes  - SingleArchModel for individual architecture experiments  - EnsembleModel with multi-architecture fusion  - FeatureFusionModule with attention/concat/weighted strategies- Implemented 4 decoder variants:  - FrequencyAwareDecoder (low/high frequency separation)  - WaveletFrequencyDecoder (4-band wavelet prediction)  - SimpleDecoder (basic transposed convolution)  - AttentionDecoder (transformer blocks + upsampling)- Built train_perceptual.py with unified training pipeline- Created evaluation.py for test set metrics (PSNR, SSIM, LPIPS)- Developed main.py experiment runner with automated evaluation- Complete comparison report generation with CSV exportsTraining Configuration- Device: NVIDIA RTX Ada 6000 (48GB)- Base config: 30 epochs, batch size 4, lr 0.0001- Loss: MSE (0.5) + LPIPS (0.5) with AlexNet backbone- Optimizer: Adam with ReduceLROnPlateau scheduling- Early stopping: patience 15 epochs- Dataset: DIV2K (640 train, 160 val, 100 test)Experimental Matrix- Single architectures: 8 base configs ? 4 decoders = 32 experiments  - ResNet34 (layer1, layer2)  - VGG16 (block1, block3)  - ViT-Small (block1, block3)  - PVT-v2-B2 (stage1, stage2)- Ensemble models: 3 fusion strategies ? 4 decoders = 12 experiments  - Attention fusion (learnable channel-wise weighting)  - Concat fusion (concatenation + conv reduction)  - Weighted fusion (learnable scalar weights)- Total: 44 complete train/eval cyclesTop 10 Results (by PSNR)1. ensemble_all_weighted_simple:    17.64 dB, SSIM 0.5862. ensemble_all_concat_simple:      17.50 dB, SSIM 0.5843. vgg16_block1_simple:             17.35 dB, SSIM 0.5604. ensemble_all_attention_simple:   17.30 dB, SSIM 0.5705. ensemble_all_concat_freq_aware:  17.27 dB, SSIM 0.5626. ensemble_all_weighted_freq_aware: 17.25 dB, SSIM 0.5737. vgg16_block1_wavelet:            17.24 dB, SSIM 0.5728. ensemble_all_attention_wavelet:  17.24 dB, SSIM 0.5629. ensemble_all_concat_wavelet:     17.21 dB, SSIM 0.59110. ensemble_all_weighted_wavelet:  17.14 dB, SSIM 0.576Key Findings- Ensemble superiority: Best ensemble (17.64 dB) vs Run 1 (13.93 dB) = +3.71 dB (+26.6%)- Ensemble vs baseline: 17.64 dB vs 14.45 dB = +3.19 dB (+22.1%)- Fusion strategy: Weighted fusion edges out attention and concat by ~0.1-0.3 dB- Decoder analysis: Simple decoder performs best across all fusion strategies- Single arch winner: VGG16 block1 achieves 17.35 dB, competitive with ensembles- Feature diversity: Multi-architecture fusion captures complementary CNN + Transformer featuresTechnical Insights- Simple decoder sufficient when feature diversity is high- VGG16 block1 (112?112 spatial) retains more spatial information than deeper layers- Ensemble fusion bottleneck: 4 encoders ? 256ch @ 28?28 ? decoder- Memory efficient: Batch size 4 manageable on RTX Ada 6000- Training stability: All 44 experiments converged without major issuesComparative AnalysisMetric comparison (Baseline ? Run 1 ? Run 3 Best):- PSNR: 14.45 dB ? 13.93 dB ? 17.64 dB- SSIM: 0.530 ? 0.565 ? 0.586- Run 3 achieves both pixel accuracy AND perceptual qualitySaved Outputs- Checkpoints: results/{single,ensemble}/checkpoints_{exp_name}/- Evaluations: results/{single,ensemble}/evaluation_{exp_name}/- Comparison report: results/comparison_report/  - all_models_{timestamp}.csv (complete results)  - decoder_comparison_{timestamp}.csv  - architecture_comparison_{timestamp}.csv  - fusion_comparison_{timestamp}.csv
This is a screenshot of different results and once we narrow it down after speaking with the TA/professor Ð we will upload that code.Week 4 SummaryNew code: 4 Python modules (models.py, train_perceptual.py, evaluation.py, main.py), ~2500 linesExperiments: 44 complete train/eval cycles (32 single + 12 ensemble)Training time: ~XX hours total on RTX Ada 6000Key result: Ensemble achieves 17.64 dB PSNR, +26.6% improvement over Run 1Best model: ensemble_all_weighted_simple (weighted fusion + simple decoder)Next Steps- Investigate why simple decoder outperforms complex variants- Analyze feature visualizations to understand complementarity- Statistical significance testing between top-5 models- Extend to higher resolution reconstruction (448?448 or 512?512)- Literature comparison with state-of-the-art feature inversion methods================================================================================